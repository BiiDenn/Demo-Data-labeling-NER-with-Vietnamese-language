import streamlit as st
import pandas as pd
import re
import pytesseract
from PIL import Image
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# âœ… Cáº¥u hÃ¬nh Tesseract (náº¿u cÃ i á»Ÿ vá»‹ trÃ­ khÃ¡c, hÃ£y chá»‰nh láº¡i Ä‘Æ°á»ng dáº«n nÃ y)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

st.set_page_config(page_title="AI Legal Text & NER Demo", page_icon="âš–ï¸", layout="wide")

st.title("âš–ï¸ á»¨NG Dá»¤NG Há»ŒC SÃ‚U TRONG Xá»¬ LÃ VÄ‚N Báº¢N PHÃP LÃ & RÃšT TRÃCH THá»°C THá»‚ TIáº¾NG VIá»†T")

tab1, tab2, tab3 = st.tabs(["ğŸ·ï¸ GÃ¡n nhÃ£n dá»¯ liá»‡u", "ğŸ” NER Rule-based (OCR)", "ğŸ¤– NER Transformer (OCR + PhoBERT)"])

# ======================
# TAB 1 â€” Data Labeling
# ======================
with tab1:
    st.header("ğŸ·ï¸ GÃN NHÃƒN Dá»® LIá»†U (Data Labeling Demo)")
    st.markdown("Minh há»a quÃ¡ trÃ¬nh **gÃ¡n nhÃ£n dá»¯ liá»‡u thá»§ cÃ´ng** cho cÃ¡c máº«u email â€” bÆ°á»›c ná»n táº£ng cho mÃ´ hÃ¬nh AI há»c cÃ³ giÃ¡m sÃ¡t.")

    emails = [
        "TÃ i khoáº£n cá»§a báº¡n Ä‘Ã£ bá»‹ khÃ³a, vui lÃ²ng Ä‘Äƒng nháº­p táº¡i http://abc.com Ä‘á»ƒ xÃ¡c nháº­n.",
        "Khuyáº¿n mÃ£i 50% cho Ä‘Æ¡n hÃ ng hÃ´m nay! NgoÃ i ra, báº¥m vÃ o http://abc.com Ä‘á»ƒ nháº­n thÆ°á»Ÿng $1000.",
        "Xin chÃ o, Ä‘Ã¢y lÃ  hÃ³a Ä‘Æ¡n thÃ¡ng 10 cá»§a báº¡n.",
        "Vui lÃ²ng xÃ¡c minh thÃ´ng tin ngÃ¢n hÃ ng cá»§a báº¡n táº¡i Ä‘Æ°á»ng dáº«n dÆ°á»›i Ä‘Ã¢y."
    ]
    true_labels = ["ğŸš¨ Spam/Giáº£ máº¡o", "ğŸš¨ Spam/Giáº£ máº¡o", "âœ… BÃ¬nh thÆ°á»ng", "ğŸš¨ Spam/Giáº£ máº¡o"]

    if "labels" not in st.session_state:
        st.session_state.labels = [None] * len(emails)

    for i, email in enumerate(emails):
        st.write(f"**Email {i+1}:** {email}")
        label = st.radio(
            f"Chá»n nhÃ£n cho email {i+1}",
            ["ChÆ°a gÃ¡n", "ğŸš¨ Spam/Giáº£ máº¡o", "âœ… BÃ¬nh thÆ°á»ng"],
            key=f"email_{i}"
        )
        if label != "ChÆ°a gÃ¡n":
            st.session_state.labels[i] = label

    if st.button("ğŸ“Š Hiá»ƒn thá»‹ káº¿t quáº£ gÃ¡n nhÃ£n"):
        user_labels = st.session_state.labels
        comparison = ["âœ… ÄÃºng" if user_labels[i] == true_labels[i] else "âŒ Sai"
                      for i in range(len(emails))]

        df = pd.DataFrame({
            "Email": emails,
            "NhÃ£n ngÆ°á»i gÃ¡n": user_labels,
            "NhÃ£n Ä‘Ãºng": true_labels,
            "ÄÃ¡nh giÃ¡": comparison
        })

        def highlight_row(row):
            color = "#d4edda" if row["ÄÃ¡nh giÃ¡"] == "âœ… ÄÃºng" else "#f8d7da"
            return [f"background-color: {color}"] * len(row)

        st.dataframe(df.style.apply(highlight_row, axis=1), use_container_width=True)

        correct = sum(1 for c in comparison if c == "âœ… ÄÃºng")
        acc = correct / len(comparison) * 100
        st.success(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c gÃ¡n nhÃ£n: **{acc:.1f}%**")

# ============================
# TAB 2 â€” Rule-based with OCR
# ============================
# ============================
# TAB 2 â€” Rule-based with OCR or Manual Input
# ============================
with tab2:
    st.header("ğŸ” RÃšT TRÃCH THá»°C THá»‚ â€” HÆ¯á»šNG 1: Rule-based")
    st.markdown("""
    Báº¡n cÃ³ thá»ƒ **táº£i hÃ¬nh áº£nh vÄƒn báº£n phÃ¡p lÃ½ (JPG/PNG)** hoáº·c **nháº­p trá»±c tiáº¿p ná»™i dung vÄƒn báº£n** Ä‘á»ƒ há»‡ thá»‘ng trÃ­ch xuáº¥t tÃªn ngÆ°á»i, tá»• chá»©c, Ä‘á»‹a Ä‘iá»ƒm.
    """)

    mode = st.radio("Chá»n phÆ°Æ¡ng thá»©c nháº­p dá»¯ liá»‡u:", ["ğŸ“„ Táº£i áº£nh", "âœï¸ Nháº­p vÄƒn báº£n"], key="mode_rule")

    extracted_text = ""

    if mode == "ğŸ“„ Táº£i áº£nh":
        uploaded_img = st.file_uploader("ğŸ“ Chá»n áº£nh vÄƒn báº£n phÃ¡p lÃ½ (JPG/PNG)", type=["jpg", "jpeg", "png"], key="img_rule")
        if uploaded_img is not None:
            img = Image.open(uploaded_img)
            st.image(img, caption="ğŸ“œ áº¢nh vÄƒn báº£n Ä‘Æ°á»£c táº£i lÃªn", use_column_width=True)
            with st.spinner("ğŸ”  Äang Ä‘á»c ná»™i dung vÄƒn báº£n tá»« áº£nh (OCR)..."):
                extracted_text = pytesseract.image_to_string(img, lang="vie")

    else:
        extracted_text = st.text_area("âœï¸ Nháº­p ná»™i dung vÄƒn báº£n táº¡i Ä‘Ã¢y:", height=250)

    if st.button("ğŸ” RÃºt trÃ­ch thá»±c thá»ƒ (Rule-based)"):
        if not extracted_text.strip():
            st.warning("âš ï¸ Vui lÃ²ng táº£i áº£nh hoáº·c nháº­p ná»™i dung vÄƒn báº£n trÆ°á»›c.")
        else:
            # --- Regex nháº­n dáº¡ng thá»±c thá»ƒ ---
            pattern_person = r"\b([A-ZÄ][a-zÃ Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ä‘Ãªá»áº¿á»ƒá»…á»‡Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Æ°á»«á»©á»­á»¯á»±]+(?:\s[A-ZÄ][a-zÃ Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ä‘Ãªá»áº¿á»ƒá»…á»‡Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Æ°á»«á»©á»­á»¯á»±]+){1,3})\b"
            pattern_org = r"\b(Há»c\s?viá»‡n\s[A-ZÄa-z\s]+|PhÃ²ng\s[A-ZÄa-z\-]+\s?[A-ZÄa-z\-]*|TrÆ°á»ng\s[A-ZÄa-z\s]+|CÃ´ng\s?[Tt]y\s[A-ZÄa-z\s]+|Bá»™\s[A-ZÄa-z\s]+|Sá»Ÿ\s[A-ZÄa-z\s]+|á»¦y\sban\s[A-ZÄa-z\s]+)\b"
            pattern_loc = r"\b(TP\.?\s?Há»“\s?ChÃ­\s?Minh|HÃ \s?Ná»™i|ÄÃ \s?Náºµng|Huáº¿|Quáº­n\s?\d+)\b"

            persons = re.findall(pattern_person, extracted_text)
            orgs = re.findall(pattern_org, extracted_text)
            locs = re.findall(pattern_loc, extracted_text)

            # --- Highlight káº¿t quáº£ ---
            highlighted = extracted_text
            for p in persons:
                highlighted = highlighted.replace(p, f"<span style='color:green; font-weight:bold'>{p}</span>")
            for o in orgs:
                highlighted = highlighted.replace(o, f"<span style='color:orange; font-weight:bold'>{o}</span>")
            for l in locs:
                highlighted = highlighted.replace(l, f"<span style='color:purple; font-weight:bold'>{l}</span>")

            st.markdown("### ğŸ§© Káº¿t quáº£ trÃ­ch xuáº¥t (Rule-based):", unsafe_allow_html=True)
            st.markdown(highlighted, unsafe_allow_html=True)
            st.write("**ğŸ‘¤ NgÆ°á»i (PER):**", persons)
            st.write("**ğŸ¢ Tá»• chá»©c (ORG):**", orgs)
            st.write("**ğŸ“ Äá»‹a Ä‘iá»ƒm (LOC):**", locs)


# =========================================
# TAB 3 â€” Transformer-based NER with OCR or Manual Input
# =========================================
with tab3:
    st.header("ğŸ¤– RÃšT TRÃCH THá»°C THá»‚ â€” HÆ¯á»šNG 2: Transformer PhoBERT")
    st.markdown("""
    Báº¡n cÃ³ thá»ƒ **táº£i áº£nh vÄƒn báº£n phÃ¡p lÃ½ (OCR)** hoáº·c **nháº­p trá»±c tiáº¿p ná»™i dung vÄƒn báº£n** Ä‘á»ƒ mÃ´ hÃ¬nh há»c sÃ¢u PhoBERT tá»± Ä‘á»™ng trÃ­ch xuáº¥t thá»±c thá»ƒ.
    """)

    mode2 = st.radio("Chá»n phÆ°Æ¡ng thá»©c nháº­p dá»¯ liá»‡u:", ["ğŸ“„ Táº£i áº£nh", "âœï¸ Nháº­p vÄƒn báº£n"], key="mode_trans")

    text_input = ""

    if mode2 == "ğŸ“„ Táº£i áº£nh":
        uploaded_img2 = st.file_uploader("ğŸ“ Chá»n áº£nh vÄƒn báº£n (JPG/PNG)", type=["jpg", "jpeg", "png"], key="img_trans")
        if uploaded_img2 is not None:
            img2 = Image.open(uploaded_img2)
            st.image(img2, caption="ğŸ“œ áº¢nh vÄƒn báº£n Ä‘Æ°á»£c táº£i lÃªn", use_column_width=True)
            with st.spinner("ğŸ”  Äang Ä‘á»c vÄƒn báº£n (OCR)..."):
                text_input = pytesseract.image_to_string(img2, lang="vie")
    else:
        text_input = st.text_area("âœï¸ Nháº­p ná»™i dung vÄƒn báº£n táº¡i Ä‘Ã¢y:", height=250, key="manual_text")

    if "ner_pipeline" not in st.session_state:
        with st.spinner("ğŸ”„ Äang táº£i mÃ´ hÃ¬nh Transformer NER (PhoBERT)..."):
            tokenizer = AutoTokenizer.from_pretrained("NlpHUST/ner-vietnamese-electra-base", trust_remote_code=True)
            model = AutoModelForTokenClassification.from_pretrained("NlpHUST/ner-vietnamese-electra-base", trust_remote_code=True)
            st.session_state.ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

    if st.button("ğŸš€ RÃºt trÃ­ch thá»±c thá»ƒ báº±ng Transformer PhoBERT"):
        if not text_input.strip():
            st.warning("âš ï¸ Vui lÃ²ng táº£i áº£nh hoáº·c nháº­p vÄƒn báº£n trÆ°á»›c.")
        else:
            ner = st.session_state.ner_pipeline

            # --- Chia nhá» Ä‘oáº¡n dÃ i ---
            chunks = []
            text_clean = text_input.replace("\n", " ").strip()
            while len(text_clean) > 0:
                chunk = text_clean[:450]
                end_idx = chunk.rfind(" ")
                if end_idx == -1: end_idx = len(chunk)
                chunks.append(text_clean[:end_idx])
                text_clean = text_clean[end_idx:].strip()

            all_results = []
            for chunk in chunks:
                results = ner(chunk)
                for r in results:
                    r["chunk"] = chunk
                all_results.extend(results)

            df = pd.DataFrame(all_results)

            highlighted_text = text_input
            for r in all_results:
                color = {"PER": "green", "ORG": "orange", "LOC": "purple"}.get(r["entity_group"], "blue")
                highlighted_text = highlighted_text.replace(r["word"], f"<span style='color:{color}; font-weight:bold'>{r['word']}</span>")

            st.markdown("### ğŸ§© Káº¿t quáº£ trÃ­ch xuáº¥t (Transformer PhoBERT):", unsafe_allow_html=True)
            st.markdown(highlighted_text, unsafe_allow_html=True)

            if not df.empty:
                st.dataframe(df[["word", "entity_group", "score"]], use_container_width=True)
